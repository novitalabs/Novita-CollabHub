export const UTM_PARAMS = "?utm_source=github_collabhub&utm_medium=readme&utm_campaign=collab";

![](static/logo.png)

[ùïè <u>Follow me on X</u>](https://x.com/novita_labs{UTM_PARAMS}) ‚Ä¢ [ü§ó <u>Hugging Face</u>](https://huggingface.co/novita{UTM_PARAMS}) ‚Ä¢ [üíª <u>Docs</u>](https://novita.ai/docs/guides/introduction{UTM_PARAMS})

[Novita AI](https://novita.ai{UTM_PARAMS}) is an AI cloud platform that helps developers easily deploy AI models through a simple API, backed by affordable and reliable GPU cloud infrastructure.

## **TOP-LLM Integration Repo**

Integrate the Novita API into popular software and platforms. Access [Novita](https://novita.ai/settings/key-management{UTM_PARAMS}) to get an API key.

| **Repo**<br/>                                    | **Description**<br/>                                                                                                                              | **Link**<br/>                                                                                                                                                                        | Guide<br/>                                                                                                                                                      |
| ------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| ![](static/hf.png)<br/> | Hugging Face is a library that provides pre-trained language models for NLP tasks. Novita is one of the inference providers of Hugging Face.<br/> | [https://github.com/huggingface](https://github.com/huggingface)<br/>[https://huggingface.co/models?inference_provider=novita](https://huggingface.co/models?inference_provider=novita)<br/> | [Novita AI & Hugging Face Integration Guide](https://novita.ai/docs/guides/huggingface/{UTM_PARAMS})<br/> |
| ![](static/langchain.png)<br/> | LangChain is a framework for developing applications powered by large language models (LLMs).<br/>                                                | [https://github.com/langchain-ai/langchain](https://github.com/langchain-ai/langchain)<br/>                                                                                              | [Novita AI & LangChain Integration Guide](https://novita.ai/docs/guides/langchain/{UTM_PARAMS})<br/>      |
| ![](static/lobechat.png)<br/> | LobeChat is an open-source, modern-design AI chat framework.<br/>                                                                                 | [https://github.com/lobehub/lobe-chat](https://github.com/lobehub/lobe-chat)<br/>                                                                                                        | [Novita AI & LobeChat Integration Guide](https://novita.ai/docs/guides/lobechat/{UTM_PARAMS})<br/>        |
| ![](static/dify.png)<br/> | Dify is an open-source LLM app development platform.<br/>                                                                                         | [https://github.com/langgenius/dify](https://github.com/langgenius/dify)<br/>                                                                                                            | [Novita AI & Dify Integration Guide](https://novita.ai/docs/guides/dify/{UTM_PARAMS})<br/>                |
| ![](static/langflow.png)<br/> | Langflow is a low-code app builder for RAG and multi-agent AI applications. <br/>                                                                 | [https://github.com/langflow-ai/langflow](https://github.com/langflow-ai/langflow)<br/><br/>                                                                                             | [Novita AI & Langflow Integration Guide](https://novita.ai/docs/guides/langflow/{UTM_PARAMS})<br/>        |
| ![](static/anythingllm.png)<br/> | AnythingLLM is an all-in-one Desktop & Docker AI application with built-in RAG, AI agents, No-code agent builder, and more.<br/>                  | [https://github.com/Mintplex-Labs/anything-llm](https://github.com/Mintplex-Labs/anything-llm)<br/><br/>                                                                                 | [Novita AI & AnythingLLM Integration Guide](https://novita.ai/docs/guides/anythingllm/{UTM_PARAMS})<br/>  |
| ![](static/continue.png)<br/> | Continue is the leading open-source AI code assistant. <br/>                                                                                      | [https://github.com/continuedev/continue](https://github.com/continuedev/continue)<br/>                                                                                                  | [Novita AI & Continue Integration Guide](https://novita.ai/docs/guides/continue/{UTM_PARAMS})<br/>        |
| ![](static/skyvern.png)<br/> | Skyvern can automate browser-based workflows with LLMs and Computer Vision.<br/>                                                                  | [https://github.com/Skyvern-AI/skyvern](https://github.com/Skyvern-AI/skyvern)<br/>                                                                                                  | [Novita AI & Skyvern Integration Guide](https://novita.ai/docs/guides/skyvern/{UTM_PARAMS})<br/>          |
| ![](static/helicone.png)<br/> | Helicone is an open-source LLM observability platform.<br/>                                                                                       | [https://github.com/Helicone/helicone](https://github.com/Helicone/helicone)<br/>                                                                                                        | [Novita AI & Helicone Integration Guide](https://novita.ai/docs/guides/helicone/{UTM_PARAMS})<br/><br/>   |

## **Novita ****Instance Templates**

Templates are Docker container images paired with a configuration. They are used to launch images as instances, define the required container disk size, volume, volume paths, and ports needed. You can also define environment variables within the template.

| **Repo**<br/>                                    | **Description**<br/>                                                                              | **Link**<br/>                                                                                       | Template<br/>                                                                                                                                                                              |
| ------------------------------------------------ | ------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| ![](static/vllm.png)<br/> | vLLM is a high-throughput and memory-efficient inference and serving engine for LLMs.<br/>        | [https://github.com/vllm-project/vllm](https://github.com/vllm-project/vllm)<br/>                       | [Run DeepSeek-R1-Distill-Qwen-1.5B with vLLM on Novita](https://novita.ai/gpus-console/explore?templateId=304{UTM_PARAMS})<br/><br/> |
| ![](static/sglang.png)<br/> | SGLang is a fast serving framework for large language models and vision language models.<br/>     | [https://github.com/sgl-project/sglang](https://github.com/sgl-project/sglang)<br/>                     | [Run Llama3.1-8B-Instruct with SGLang on Novita](https://novita.ai/gpus-console/explore?templateId=310{UTM_PARAMS})<br/><br/>        |
| ![](static/tensorflow.png)<br/> | TensorFlow is an open-source machine learning framework for everyone.<br/>                        | [https://github.com/tensorflow/tensorflow](https://github.com/tensorflow/tensorflow)<br/>               | [Run Tensorflow:2.7.0 on Novita](https://novita.ai/gpus-console/explore?templateId=269{UTM_PARAMS})<br/><br/>                        |
| ![](static/pytorch.png)<br/> | PyTorch offers tensors and dynamic neural networks in Python with strong GPU acceleration.<br/>   | [https://github.com/pytorch/pytorch](https://github.com/pytorch/pytorch)<br/>                           | [Run Pytorch:2.2.1 on Novita](https://novita.ai/gpus-console/explore?templateId=268{UTM_PARAMS})<br/><br/>                           |
| ![](static/flux.png)<br/> | Flux contains minimal inference code to run image generation & editing with our Flux models.<br/> | [https://github.com/black-forest-labs/flux](https://github.com/black-forest-labs/flux)<br/>             | [Run comfyui:flux1-fp8 with Flux on Novita AI](https://novita.ai/gpus-console/explore?templateId=301{UTM_PARAMS})<br/><br/>          |
| ![](static/stable-diffusion.png)<br/> | Stabel Diffusion offers high-resolution image synthesis with latent diffusion models.<br/>        | [https://github.com/Stability-AI/stablediffusion](https://github.com/Stability-AI/stablediffusion)<br/> | [Run StableDiffusion:v1.8.0 on Novita AI](https://novita.ai/gpus-console/explore?templateId=298{UTM_PARAMS})<br/>                    |
| ![](static/face-fusion.png)<br/> | FaceFusion is the industry-leading face manipulation platform.<br/><br/>                          | [https://github.com/facefusion/facefusion](https://github.com/facefusion/facefusion)<br/>               | [Run Facefusion:v3.1.1  on Novita AI](https://novita.ai/gpus-console/explore?templateId=299{UTM_PARAMS})<br/><br/>                   |
| ![](static/cuda-samples.png)<br/> | CUDA-Samples offer samples for CUDA Developers which demonstrate features in CUDA Toolkit.<br/>   | [https://github.com/NVIDIA/cuda-samples](https://github.com/NVIDIA/cuda-samples)<br/>                   | [Run cuda:11.8.0 with CUDA-Samples on Novita AI](https://novita.ai/gpus-console/explore?templateId=270{UTM_PARAMS})<br/>             |
| ![](static/kobold-cpp.png)<br/> | KoboldCpp runs GGUF models easily with a KoboldAI UI with one file and zero Install.<br/>         | [https://github.com/LostRuins/koboldcpp](https://github.com/LostRuins/koboldcpp)<br/>                   | [Run KoboldCpp on Novita AI](https://novita.ai/gpus-console/explore?templateId=300&productId=4/{UTM_PARAMS})<br/><br/>               |

## **Getting Started**

Learn about how to use Novita AI in the docs[ ](https://novita.ai/docs/guides/introduction/{UTM_PARAMS})<u>here</u><u>.</u>

## **License**

[https://opensource.org/license/MIT](https://opensource.org/license/MIT)

## **Get in Touch **

- Email:  [iris@novita.ai](mailto:iris@novita.ai)
- Discord: <u>novita.ai</u>

We're excited to hear from you and work together to build a better cloud ecosystem. At Novita AI, we believe in the strength of teamwork. Let‚Äôs start a new journey in cloud computing together!
